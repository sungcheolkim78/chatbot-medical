# Medical Chatbot

A medical domain-specific chatbot implementation with two distinct architectures: LangChain-based for evaluation and prompt engineering, and CrewAI-based for agentic AI demonstration. The system includes a comprehensive evaluation framework for assessing different LLM models and prompt configurations.

<img src="docs/figs/medical_chatbot.png" alt="Medical Chatbot Architecture" height="400px">
(This image is generated by ChatGPT)

## Project Requirements

The details of the project requirements can be found [here](docs/project_requirements.md)

## Architecture Overview

### 1. LangChain Implementation

- **Core Components**:
  - Document Processing Pipeline
  - Vector Store Integration (FAISS)
  - Retrieval-Augmented Generation (RAG)
  - Custom Chain Implementations
  - Evaluation Framework

- **Key Features**:
  - Document chunking and embedding
  - Semantic search capabilities
  - Context-aware response generation
  - Prompt template management
  - Automated evaluation pipeline

The details of the architectural design can be found [here](docs/architectural_design.md)

### 2. CrewAI Implementation

This implementation is premature. But to demonstrate the difference between agentic AI approach and conditional flow LLM pipeline, we include the chatbot version implemented by CrewAI. It provides the basic chatbot function based on the knowledge base, but there are no evalution pipeline. 

- **Core Components**:
  - Multi-agent System
  - Task Orchestration
  - Role-based Specialization
  - Inter-agent Communication

- **Key Features**:
  - Agent-based conversation flow
  - Task delegation and coordination
  - Specialized medical knowledge agents
  
## Installation

1. Clone and setup:
```bash
git clone https://github.com/sungcheolkim78/chatbot-humana.git
cd chatbot-humana
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate
```

2. Install dependencies:
```bash
pip install -r requirements.txt
```

3. Environment Configuration:
Copy env_example to `.env` file and update the api keys.
`OPENAI_API_KEY`, `ANTHROPIC_API_KEY`, `GOOGLE_API_KEY` is used only for the evaluation
dataset generation and chatbot response evaluation.

4. Install and download open-source LLMs:
Here, we use ollama for the local LLM provider with open-source LLMs. 
For the setup, please check [this document](docs/ollama_installation.md)

## Usage

The project uses Makefile for common operations:

### LangChain Version
```bash
source .venv/bin/activate

# Start the chatbot
make chatbot_langchain

# Generate evaluation dataset
make eval_dataset

# Launch evaluation dataset viewer
make eval_dataset_app

# Run batch evaluation
make eval_batch

# Launch LLM score viewer
make eval_score_app
```

### CrewAI Version
```bash
# Start the agentic chatbot
make chatbot_crewai
```

## Screenshot of the web application

Chatbot (Langchain version) - The main chatbot application
![](docs/figs/chatbot_langchain_screenshot.png)

Dataset Viewer - The dataset viewer to validate the evaluation dataset with the source excerpts
![](docs/figs/eval_app_screenshot.png)

Chatbot Score Viewer - The chatbot response viewer with LLM Judge score
![](docs/figs/eval_score_screenshot.png)

## Evaluation Framework

We developed a tool to evaluate the chat-bot performance so that the continuous improvement can be possible. The initial step is to clean up the information for the knowledge base. We are using the seminal paper "Human Breast Cancer: Correlation of Relapse and Survival with Amplification of the HER-2/neu Oncogene" You can find the details how to preprocess the PDF [here](knowledge/README.md) 

And here are the three main metrics for the evaluation. Check marks are implemented items and the empty item is for future works. 

### 1. Response Quality Metrics
- [x] Relevance: Semantic alignment with query intent
- [x] Coherence: Logical flow and consistency
- [x] Accuracy: Factual correctness and precision

### 2. Performance Metrics
- [x] Response Time: Latency measurements
- [ ] Resource Utilization: Memory and CPU profiling
- [ ] Error Rates: Failure analysis

### 3. User Experience Metrics
- [ ] User Feedback: Structured feedback collection
- [x] Friendliness and Engagement: Interaction quality
- [x] Knowledge Adaptation: User expertise level handling

Detailed evaluation dataset generation and score calculation can be found [here](evaluation/README.md)

## Model Performance Analysis

We have conducted extensive evaluation of various open-source LLM models across multiple dimensions:

![](docs/figs/metrics_boxplot_by_model_v1.png)

Detailed performance analysis and methodology can be found in [Open Source Model Performance](docs/opensource_model_performance.md).

By continously updating the prompts and measuring the metric improvement, we can improve the chatbot system incrementally. You can find the details of the continous developement [here](docs/continous_development.md)

### Key Findings:

1. Factuality Check
   - Response Quality and Correctness based on the base LLM models and prompt engineering
   - Error Patterns

2. Prompt Engineering Impact
   - Template Effectiveness
   - Context Utilization
   - Response Consistency

3. System Architecture Considerations
   - Latency Analysis
   - Scalability
   - Integration Complexity

## Future Works

### Integration of the Unified Clinical Vocabulary Embeddings

From the publication [1](knowledge/johnson2024.pdf), we can expand our chatbot to handle the multiple knowlege base documents with better precision. 

**Three insight from the paper:**
1. The typical embeddings used by the current AI fields such as OpenAI, Voyage embeddings can not capture the medical meanings and relationships between the medical concepts. 
1. In the paper, they trained the graph network based transformer model and generate the latent embeddings through self-supervised learning to overcome the current embedding methods in clinical domain. 
1. this embedding can also solve two major challenges in the field; one the personal information issue and the incompatibility between the medical instititues. 

**Importance to the insurance company:**
The last point of the insight is critical to the commercial insurance company. The privacy of the patient information is critical and the chatbot system does not allow the inputs of the individual medical information. However, this medical embeddings does not use the patient's information during the training process and we can keep the patient's data securaly. As mentioned in the publication, this embeddings still have correlation between the medical concepts and disease types. The chatbot based on this embedding can provide the precision medicine and personalized assistance. 

**Application to the chatbot:**
One of the limitation of our current chatbot is that the knowledge base is a single publication. To expand multiple papers with scalable services, we need to implement the effiecient retrieval system. Currently, we use FAISS with huggingface embeddings over the whole contents of the single paper. 

We can implement two levels of retrieval system. One is the paper-level embedding match and the other one is the chunk-level embedding match. By applying the unified clinical vocabulary embeddings (UCVE) to each paper, we can find the embeddings. And using the additive property of the embeddings, we can create a single final embedding for the paper. By checking the cosine similarity between the query embedding and paper-level embeddings, we can find the relavant top k (k=2 or 3) papers. Then we can use the typical embeddings from the chunks from those papers. The seconds method is to create cohort of chunks from the all knowledge papers and get the UCVE embeddings for the chunks. Then we can find the relavant chunks by similarity search between the query and the chunk DB. 

The first approach is more scalable to the large collection of the papers, but it has lower accuracy or noiser embedding matching. The second approach need huge vector database system and slower response time, but it can provide the more relavant knowledge to the query. 


## Development Guidelines

### Code Structure
```
medical_chatbot/
├── src/
│   ├── chatbot_langchain/
│   │   ├── app.py
│   │   ├── batch.py
│   │   └── components/
│   └── chatbot_crewai/
│       ├── main.py
│       ├── crew.py
│       └── config/
├── knowledge/
│   ├── slamon1987.pdf
│   └── slamon1987_claude.md
├── evaluation/
│   ├── configs/
│   ├── chatbot_results/
│   ├── datasets/
│   ├── components/
│   ├── dataset_generator.py
│   ├── app_eval.py
│   └── llm_scorer.py
├── docs/
│   ├── figs/
│   └── opensource_model_performance.md
├── tests/
└── Makefile
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Implement changes with tests
4. Submit a pull request

## Contact

For technical inquiries: sungcheol.kim78@gmail.com
